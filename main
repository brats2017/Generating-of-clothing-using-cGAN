
from numpy import expand_dims
from numpy import zeros
from numpy import ones
from numpy.random import randn
from numpy.random import randint
from keras.datasets.fashion_mnist import load_data
from keras.optimizers import Adam
from keras.models import Model
from keras.layers import Input
from keras.layers import Dense
from keras.layers import Reshape
from keras.layers import Flatten
from keras.layers import Conv2D
from keras.layers import Conv2DTranspose
from keras.layers import LeakyReLU
from keras.layers import Dropout
from keras.layers import Embedding
from keras.layers import Concatenate
from numpy import asarray
from numpy.random import randint
from keras.models import load_model
from matplotlib import pyplot


def generator(latent_dim, n_classes=10):
	input_label = Input(shape=(1,))
	categorical_input = Embedding(n_classes, 50)(input_label)
	number_nodes = 7 * 7
	categorical_input = Dense(number_nodes)(categorical_input)
	categorical_input = Reshape((7, 7, 1))(categorical_input)
	input_latent = Input(shape=(latent_dim,))
	number_nodes = 128 * 7 * 7
	gen = Dense(number_nodes)(input_latent)
	gen = LeakyReLU(alpha=0.2)(gen)
	gen = Reshape((7, 7, 128))(gen)
	merge = Concatenate()([gen, categorical_input])
	gen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(merge)
	gen = LeakyReLU(alpha=0.2)(gen)
	gen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(gen)
	gen = LeakyReLU(alpha=0.2)(gen)
	out_layer = Conv2D(1, (7,7), activation='tanh', padding='same')(gen)
	model = Model([input_latent, input_label], out_layer)
	return model


def discriminator(in_shape=(28,28,1), n_classes=10):
	input_label = Input(shape=(1,))
	categorical_input = Embedding(n_classes, 50)(input_label)
	number_nodes = in_shape[0] * in_shape[1]
	categorical_input = Dense(number_nodes)(categorical_input)
	categorical_input = Reshape((in_shape[0], in_shape[1], 1))(categorical_input)
	input_image = Input(shape=in_shape)
	merge = Concatenate()([input_image, categorical_input])
	L = Conv2D(128, (3,3), strides=(2,2), padding='same')(merge)
	L = LeakyReLU(alpha=0.2)(L)
	L = Conv2D(128, (3,3), strides=(2,2), padding='same')(L)
	L = LeakyReLU(alpha=0.2)(L)
	L = Flatten()(L)
	L = Dropout(0.4)(L)
	out_layer = Dense(1, activation='sigmoid')(L)
	model = Model([input_image, input_label], out_layer)
	optimization = Adam(lr=0.0002, beta_1=0.5)
	model.compile(loss='binary_crossentropy', optimizer=optimization, metrics=['accuracy'])
	return model



def gan(g_model, d_model):
	d_model.trainable = False
	gen_noise, gen_label = g_model.input
	gen_output = g_model.output
	gan_output = d_model([gen_output, gen_label])
	model = Model([gen_noise, gen_label], gan_output)
	opt = Adam(lr=0.0002, beta_1=0.5)
	model.compile(loss='binary_crossentropy', optimizer=opt)
	return model

def load_real_samples():
	(trainX, trainy), (_, _) = load_data()
	X = expand_dims(trainX, axis=-1)
	X = X.astype('float32')
	X = (X - 127.5) / 127.5
	return [X, trainy]


def generate_real_samples(dataset, n_samples):
	images, labels = dataset
	ix = randint(0, images.shape[0], n_samples)
	X, labels = images[ix], labels[ix]
	y = ones((n_samples, 1))
	return [X, labels], y


def generate_latent_points(latent_dim, n_samples, n_classes=8):
	x_input = randn(latent_dim * n_samples)
	z_input = x_input.reshape(n_samples, latent_dim)
	labels = randint(0, n_classes, n_samples)
	return [z_input, labels]


def generate_fake_samples(generator, latent_dim, n_samples):
	z_input, labels_input = generate_latent_points(latent_dim, n_samples)
	images = generator.predict([z_input, labels_input])
	y = zeros((n_samples, 1))
	return [images, labels_input], y


def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=64, n_batch=256):
	bat_per_epo = int(dataset[0].shape[0] / n_batch)
	half_batch = int(n_batch / 2)
	
	for i in range(n_epochs):
		
		for j in range(bat_per_epo):
			
			[X_real, labels_real], y_real = generate_real_samples(dataset, half_batch)
			d_loss1, _ = d_model.train_on_batch([X_real, labels_real], y_real)
			[X_fake, labels], y_fake = generate_fake_samples(g_model, latent_dim, half_batch)
			d_loss2, _ = d_model.train_on_batch([X_fake, labels], y_fake)
			[z_input, labels_input] = generate_latent_points(latent_dim, n_batch)
			y_gan = ones((n_batch, 1))
			g_loss = gan_model.train_on_batch([z_input, labels_input], y_gan)
			print('>%d, %d/%d, d1=%.3f, d2=%.3f g=%.3f' %
				(i+1, j+1, bat_per_epo, d_loss1, d_loss2, g_loss))

	g_model.save('cgan_generator.h5')


latent_dim = 64
d_model = discriminator()
g_model = generator(latent_dim)
gan_model = gan(g_model, d_model)
dataset = load_real_samples()
train(g_model, d_model, gan_model, dataset, latent_dim)


def save_plot(examples, n):

	for i in range(n * n):
		pyplot.subplot(n, n, 1 + i)
		pyplot.axis('off')
		pyplot.imshow(examples[i, :, :, 0], cmap='gray_r')
	pyplot.show()
 

model = load_model('cgan_generator.h5')
latent_points, labels = generate_latent_points(latent_dim, 64)
labels = asarray([x for _ in range(8) for x in range(8)])
X  = model.predict([latent_points, labels])
X = (X + 1) / 2.0
save_plot(X, 8)
